{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a96918b7-911a-4be1-94c1-7c7b064bcd22",
   "metadata": {},
   "source": [
    "### Translating and Comparing News Headlines: step by step  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f814d4a-a9ab-4c5a-894e-012b2575cb60",
   "metadata": {},
   "source": [
    "#### Comparing headlines across languages is cumbersome; doing an automated sentiment analysis on a sampling used to be very complex before the advent of ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c73e76c-f5d4-47eb-9b41-944803b290c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "import openai\n",
    "import os\n",
    "import requests\n",
    "import bs4\n",
    "import google.generativeai as genai\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "963617c3-fbca-4038-81b9-924a2083a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "# import os\n",
    "# import requests\n",
    "# import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30b69a95-b43c-470d-9a69-898f50daa2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.environ.get(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed6316da-c74c-4a7b-85c6-cc5c4de6077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fc1a8b3-9d3f-43a0-979e-e82f37b94e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('https://aljazeera.net', 'h3.article-card__title')\n"
     ]
    }
   ],
   "source": [
    "news_sites = {\n",
    "    \"chinese\" : (\"https://cn.chinadaily.com.cn\", \"div.Home_content_Item_Text h1 a\"),\n",
    "    \"arabic\": (\"https://aljazeera.net\", \"h3.article-card__title\")\n",
    "}\n",
    "print(news_sites[\"arabic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b96c430a-b70e-432b-9358-cb31659b92fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chinese': ['专题：全国政协十四届二次会议开幕会',\n",
       "  '专题：十四届全国人大二次会议新闻发布会',\n",
       "  '十四届全国人大二次会议3月5日上午开幕 会期7天',\n",
       "  '两会世界眼｜观察中国全过程人民民主的重要窗口',\n",
       "  '外交部：欢迎各国工商界继续加强对华合作',\n",
       "  '全国政协十四届二次会议首场“委员通道”集体采访活动举行',\n",
       "  '【100秒“瞧”见两会】阿拉伯记者秀中文 为报道两会做足功课',\n",
       "  '【世界看两会】外媒：中国两会是国家善治、经济社会繁荣的生动展现',\n",
       "  '法企高管：中国绿色经济及低碳领域合作已成为外资关注的“聚光点”',\n",
       "  '中国两会汇聚世界关注与期待 感受中国经济活力与韧性'],\n",
       " 'arabic': ['الحرب على غزة.. احتدام القتال غرب خان يونس وتصاعد الخلاف بمجلس الحرب الإسرائيلي',\n",
       "  'شاهد.. القسام تستهدف مدرعات الاحتلال وجنوده في تل الهوى',\n",
       "  'شاهد.. القسام تستهدف مدرعات الاحتلال وجنوده في تل الهوى',\n",
       "  'أكثر من 22 ألف شهيد من الأطفال والنساء في غزة منذ بدء العدوان',\n",
       "  'الاحتلال ينسف منازل شرق خان يونس والقسام تعلن قنص جنديين',\n",
       "  'حريق بسفينة شحن إسرائيلية بعد تعرضها لانفجارين قبالة سواحل عدن',\n",
       "  'أردوغان: تركيا تفعل ما بوسعها من أجل غزة',\n",
       "  'استقالات واسعة في طاقم متحدث الجيش الإسرائيلي',\n",
       "  'المحكمة العليا الأميركية ترفض حكم كولورادو بعدم أهلية ترامب للترشح ...',\n",
       "  'المدربون العسكريون.. نقطة ارتكاز النفوذ الإسرائيلي في أفريقيا']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_headlines():\n",
    "    headlines_by_language = {}\n",
    "    for language, (url, tag) in news_sites.items():\n",
    "        response = requests.get(url)\n",
    "        soup = bs4.BeautifulSoup(response.text, 'lxml')\n",
    "        headlines = [h.getText() for h in soup.select(tag)[:10]]\n",
    "        headlines_by_language[language] = headlines\n",
    "    return headlines_by_language\n",
    "fetch_headlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "889344ff-da73-499f-b1bc-5e28fc47cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_headlines(headlines_by_language):\n",
    "    translated_headlines = {}\n",
    "    for language, headlines in headlines_by_language.items():\n",
    "        translated_headlines[language] = []\n",
    "        for headline in headlines:\n",
    "            response = openai.Completion.create(\n",
    "                model=\"gpt-3.5-turbo-instruct\",\n",
    "                prompt=f\"Translate the following {language} headline into English: \\\"{headline}\\\"\",\n",
    "                temperature=0.3,\n",
    "                max_tokens=60\n",
    "            )\n",
    "            translated_headline = response.choices[0].text.strip()\n",
    "            translated_headlines[language].append(translated_headline)\n",
    "    return translated_headlines\n",
    "headlines_by_language = fetch_headlines()\n",
    "translated_headlines = translate_headlines(headlines_by_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aec9adb-8545-4c23-a613-5a714b421669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chinese': ['\"Special Topic: Opening Ceremony of the Second Session of the 14th National Committee of the Chinese People\\'s Political Consultative Conference\"', \"Special Topic: Press Conference of the Second Session of the 14th National People's Congress\", '\"The 14th National People\\'s Congress Second Session Opens on March 5th, Lasting 7 Days\"', '\"Two Sessions World Eye | Observing the Important Window of People\\'s Democracy in China\\'s Entire Process\"', 'Ministry of Foreign Affairs: Welcome the business communities of all countries to continue strengthening cooperation with China.', 'The first \"Committee Channel\" collective interview activity of the 14th National Committee of the Chinese People\\'s Political Consultative Conference was held.', '\"【100 Seconds of \"Seeing\" the Two Sessions】Arab Journalist Shows Off Chinese, Does Homework for Reporting on the Two Sessions\"', '\"World Watches Two Sessions: Foreign Media Views China\\'s Two Sessions as a Vivid Display of Good Governance and Prosperity in Economy and Society\"', '\"Executive of Chinese Companies: Cooperation in China\\'s Green Economy and Low-Carbon Field has Become the \"Focus\" of Foreign Investment\"', '\"China\\'s Two Sessions Gather Global Attention and Expectations, Experiencing China\\'s Economic Vitality and Resilience\"'], 'arabic': ['\"War on Gaza: Intensification of Fighting in Western Khan Younis and Escalation of Disagreement in the Israeli War Council\"', '\"Watch.. Al-Qassam targets occupation\\'s armored vehicles and soldiers in Tel al-Hawa\"', '\"Watch.. Al-Qassam targets occupation\\'s armored vehicles and soldiers in Tel al-Hawa\"', '\"Over 22,000 Children and Women Martyred in Gaza Since the Beginning of the Aggression\"', '\"Occupation demolishes homes in eastern Khan Yunis, Hamas declares targeting of two soldiers\"', '\"Fire on Israeli Cargo Ship After Being Hit by Two Explosions off the Coast of Aden\"', '\"Erdogan: Turkey Does Everything in its Power for Gaza\"', '\"Widespread Resignations in the Israeli Army Spokesperson\\'s Team\"', '\"US Supreme Court Rejects Colorado\\'s Ruling on Trump\\'s Eligibility for Nomination...\"', '\"Military Trainers... The Key Point of Israeli Influence in Africa\"']}\n"
     ]
    }
   ],
   "source": [
    "print(translated_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14530342-b9a7-4dc0-8f74-c9cc2009b205",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# def analyze_sentiment_and_print(translated_headlines):\n",
    "#     sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\")\n",
    "    \n",
    "#     for language, headlines in translated_headlines.items():\n",
    "#         # print(f\"Language: {language}\")\n",
    "#         for headline in headlines:\n",
    "#             sentiment = sentiment_pipeline(headline)\n",
    "#             print(f\"Language: {language}\")\n",
    "#             print(f\"Headline: '{headline}'\")\n",
    "#             print(f\"Label: {sentiment[0]['label']}, Score: {sentiment[0]['score']:.2f}\")\n",
    "#             print(\"---\")  # Separator for readability\n",
    "    \n",
    "\n",
    "# # Assuming translated_headlines is your dictionary of translated headlines\n",
    "# analyze_sentiment_and_print(translated_headlines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a25dfa-7bd0-4a79-ab18-499f7565451f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "335ead39-2941-4509-872d-095c603cb6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def analyze_sentiment_and_score_to_dataframe(translated_headlines):\n",
    "#   sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\")\n",
    "#   data = []\n",
    "\n",
    "#   for language, headlines in translated_headlines.items():\n",
    "#     # Count sentiment categories\n",
    "#     positive_count = 0\n",
    "#     negative_count = 0\n",
    "#     neutral_count = 0\n",
    "\n",
    "#     # Analyze each headline\n",
    "#     for headline in headlines:\n",
    "#       sentiment = sentiment_pipeline(headline)\n",
    "#       label = sentiment[0]['label']\n",
    "#       score = sentiment[0]['score']\n",
    "\n",
    "#       # Assign custom score based on label and score\n",
    "\n",
    "#       if label == 'negative':\n",
    "#         if score > 0.7:\n",
    "#           categ_score = -2\n",
    "#         else:\n",
    "#           categ_score = -1\n",
    "#         negative_count += 1\n",
    "#       elif label == 'positive':\n",
    "#         if score > 0.7:\n",
    "#           categ_score = 3\n",
    "#         else:\n",
    "#           categ_score = 2\n",
    "#         positive_count += 1\n",
    "#       else:\n",
    "#         categ_score = 1\n",
    "#         neutral_count += 1\n",
    "\n",
    "#       # Create a dictionary for each headline and its analysis\n",
    "#       result = {\n",
    "#           'language': language,\n",
    "#           \"text\": headline,\n",
    "#           \"label\": label,\n",
    "#           \"score\": score,\n",
    "#           \"categ_score\": categ_score\n",
    "#       }\n",
    "#       data.append(result)\n",
    "\n",
    "#     # Create DataFrame with sentiment counts as additional columns\n",
    "#     df = pd.DataFrame(data)\n",
    "#     df['positive_count'] = positive_count\n",
    "#     df['negative_count'] = negative_count\n",
    "#     df['neutral_count'] = neutral_count\n",
    "\n",
    "#     # Print sentiment category counts (optional)\n",
    "#     print(f\"{language} headlines: {positive_count} positive, {negative_count} negative, {neutral_count} neutral\")\n",
    "\n",
    "#   return df\n",
    "\n",
    "# # Assuming translated_headlines is your dictionary of translated headlines\n",
    "# df = analyze_sentiment_and_score_to_dataframe(translated_headlines)\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1f0e6b-22c4-46cb-81c3-2f34d29f2e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b158f66-b28d-44e1-8eee-308c813c53df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def analyze_sentiment_and_score_to_dataframes(translated_headlines):\n",
    "#   sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\")\n",
    "#   chinese_data = []\n",
    "#   arabic_data = []\n",
    "\n",
    "#   for language, headlines in translated_headlines.items():\n",
    "#     # Count sentiment categories\n",
    "#     positive_count = 0\n",
    "#     negative_count = 0\n",
    "#     neutral_count = 0\n",
    "\n",
    "#     # Analyze each headline\n",
    "#     for headline in headlines:\n",
    "#       sentiment = sentiment_pipeline(headline)\n",
    "#       label = sentiment[0]['label']\n",
    "#       score = sentiment[0]['score']\n",
    "\n",
    "#       # Assign custom score based on label and score\n",
    "\n",
    "#       if label == 'negative':\n",
    "#         if score > 0.7:\n",
    "#           categ_score = -2\n",
    "#         else:\n",
    "#           categ_score = -1\n",
    "#         negative_count += 1\n",
    "#       elif label == 'positive':\n",
    "#         if score > 0.7:\n",
    "#           categ_score = 3\n",
    "#         else:\n",
    "#           categ_score = 2\n",
    "#         positive_count += 1\n",
    "#       else:\n",
    "#         categ_score = 1\n",
    "#         neutral_count += 1\n",
    "\n",
    "#       # Create a dictionary for each headline and its analysis\n",
    "#       result = {\n",
    "#           'language': language,\n",
    "#           \"text\": headline,\n",
    "#           \"label\": label,\n",
    "#           \"score\": score,\n",
    "#           \"categ_score\": categ_score\n",
    "#       }\n",
    "\n",
    "#       # Append data based on language\n",
    "#       if language == 'chinese':\n",
    "#         chinese_data.append(result)\n",
    "#       else:\n",
    "#         arabic_data.append(result)\n",
    "\n",
    "#     # Create DataFrames and add sentiment counts\n",
    "#     chinese_df = pd.DataFrame(chinese_data)\n",
    "#     chinese_df['positive_count'] = positive_count\n",
    "#     chinese_df['negative_count'] = negative_count\n",
    "#     chinese_df['neutral_count'] = neutral_count\n",
    "\n",
    "#     arabic_df = pd.DataFrame(arabic_data)\n",
    "#     arabic_df['positive_count'] = positive_count\n",
    "#     arabic_df['negative_count'] = negative_count\n",
    "#     arabic_df['neutral_count'] = neutral_count\n",
    "\n",
    "#     # Print sentiment category counts as formatted strings\n",
    "#     print(f\"{language} headlines: {positive_count} positive, {negative_count} negative, {neutral_count} neutral\")\n",
    "\n",
    "#   return chinese_df, arabic_df\n",
    "\n",
    "\n",
    "# # Assuming translated_headlines is your dictionary of translated headlines\n",
    "# chinese_df, arabic_df = analyze_sentiment_and_score_to_dataframes(translated_headlines)\n",
    "# print(chinese_df)\n",
    "# print(arabic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfe18ba1-7d93-46d0-a0c9-2a68a457efec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chinese_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mchinese_df\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chinese_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(chinese_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0da241-2ae7-4b6e-999c-375708c470f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e77641-d475-4179-bc54-4b10947ebcd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c845967-8772-477b-bc92-355af3615d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_and_score(translated_headlines):\n",
    "  sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\")\n",
    "  data = []\n",
    "\n",
    "  for language, headlines in translated_headlines.items():\n",
    "    # Count sentiment categories\n",
    "    positive = 0\n",
    "    negative  = 0\n",
    "    neutral = 0\n",
    "\n",
    "    # Analyze each headline\n",
    "    for headline in headlines:\n",
    "      sentiment = sentiment_pipeline(headline)\n",
    "      label = sentiment[0]['label']\n",
    "      score = sentiment[0]['score']\n",
    "\n",
    "      # Assign custom score based on label and score\n",
    "\n",
    "      if label == 'negative':\n",
    "        if score > 0.7:\n",
    "          categ_score = -2\n",
    "        else:\n",
    "          categ_score = -1\n",
    "        negative += 1\n",
    "      elif label == 'positive':\n",
    "        if score > 0.7:\n",
    "          categ_score = 3\n",
    "        else:\n",
    "          categ_score = 2\n",
    "        positive += 1\n",
    "      else:\n",
    "        categ_score = 1\n",
    "        neutral += 1\n",
    "\n",
    "      # Create a dictionary for each headline and its analysis\n",
    "      result = {\n",
    "          'language': language,\n",
    "          \"text\": headline,\n",
    "          \"label\": label,\n",
    "          \"score\": score,\n",
    "          \"categ_score\": categ_score\n",
    "      }\n",
    "      data.append(result)\n",
    "    # print(data)\n",
    "    return data\n",
    "\n",
    "data = analyze_sentiment_and_score(translated_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d81709ba-f7a3-4c0f-aa03-ba00dbf12ea0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aabd6ad3-b8aa-4011-bf33-69e2222361ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'chinese', 'text': '\"Special Topic: Opening Ceremony of the Second Session of the 14th National Committee of the Chinese People\\'s Political Consultative Conference\"', 'label': 'neutral', 'score': 0.9023157954216003, 'categ_score': 1}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8922ae07-1c29-497b-9c7f-cbef65cd97b9",
   "metadata": {},
   "source": [
    "### Scoping issue with \"print\" command below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf82d1a9-c413-4e04-ae6e-ff8f7afdb6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_df_by_language(data):\n",
    "#     # Separate data by language\n",
    "#     chinese_data = [row for row in data if row['language'] == 'chinese']\n",
    "#     arabic_data = [row for row in data if row['language'] == 'arabic']\n",
    "\n",
    "#     # Create DataFrames and add sentiment counts\n",
    "#     chinese_df = pd.DataFrame(chinese_data)\n",
    "#     chinese_df['positive'] = len([row for row in chinese_data if row['label'] == 'positive'])\n",
    "#     chinese_df['negative'] = len([row for row in chinese_data if row['label'] == 'negative'])\n",
    "#     chinese_df['neutral'] = len([row for row in chinese_data if row['label'] == 'neutral'])\n",
    "\n",
    "#     arabic_df = pd.DataFrame(arabic_data)\n",
    "#     arabic_df['positive'] = len([row for row in arabic_data if row['label'] == 'positive'])\n",
    "#     arabic_df['negative'] = len([row for row in arabic_data if row['label'] == 'negative'])\n",
    "#     arabic_df['neutral'] = len([row for row in arabic_data if row['label'] == 'neutral'])\n",
    "\n",
    "#     # Print sentiment category counts as formatted strings\n",
    "#     print(f\"Chinese headlines: {chinese_df['positive'].iloc[0]} positive, {chinese_df['negative'].iloc[0]} negative, {chinese_df['neutral'].iloc[0]} neutral\")\n",
    "#     print(f\"Arabic headlines: {arabic_df['positive'].iloc[0]} positive, {arabic_df['negative'].iloc[0]} negative, {arabic_df['neutral'].iloc[0]} neutral\")\n",
    "\n",
    "#     return chinese_df, arabic_df\n",
    "\n",
    "# chinese_df, arabic_df = create_df_by_language(data)\n",
    "# print(\"DATAFRAME\")\n",
    "# # print(chinese_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2926178-9998-4cf8-a40f-3b4af0dee442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81e4814e-b2c3-41ec-bc98-7e7018986630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHINESE DATAFRAME:\n",
      "  language                                               text     label  \\\n",
      "0  chinese  \"Special Topic: Opening Ceremony of the Second...   neutral   \n",
      "1  chinese  Special Topic: Press Conference of the Second ...   neutral   \n",
      "2  chinese  \"The 14th National People's Congress Second Se...   neutral   \n",
      "3  chinese  \"Two Sessions World Eye | Observing the Import...   neutral   \n",
      "4  chinese  Ministry of Foreign Affairs: Welcome the busin...  positive   \n",
      "5  chinese  The first \"Committee Channel\" collective inter...   neutral   \n",
      "6  chinese  \"【100 Seconds of \"Seeing\" the Two Sessions】Ara...   neutral   \n",
      "7  chinese  \"World Watches Two Sessions: Foreign Media Vie...  positive   \n",
      "8  chinese  \"Executive of Chinese Companies: Cooperation i...   neutral   \n",
      "9  chinese  \"China's Two Sessions Gather Global Attention ...  positive   \n",
      "\n",
      "      score  categ_score  positive  negative  neutral  \n",
      "0  0.902316            1         3         0        7  \n",
      "1  0.883254            1         3         0        7  \n",
      "2  0.837113            1         3         0        7  \n",
      "3  0.758375            1         3         0        7  \n",
      "4  0.740383            3         3         0        7  \n",
      "5  0.888999            1         3         0        7  \n",
      "6  0.755247            1         3         0        7  \n",
      "7  0.565547            2         3         0        7  \n",
      "8  0.562612            1         3         0        7  \n",
      "9  0.811760            3         3         0        7  \n",
      "ARABIC DATAFRAME:\n",
      "Empty DataFrame\n",
      "Columns: [positive, negative, neutral]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "def create_df_by_language(data):\n",
    "    # Separate data by language\n",
    "    chinese_data = [row for row in data if row['language'] == 'chinese']\n",
    "    arabic_data = [row for row in data if row['language'] == 'arabic']\n",
    "\n",
    "    # Create DataFrames and add sentiment counts\n",
    "    chinese_df = pd.DataFrame(chinese_data)\n",
    "    chinese_df['positive'] = len([row for row in chinese_data if row['label'] == 'positive'])\n",
    "    chinese_df['negative'] = len([row for row in chinese_data if row['label'] == 'negative'])\n",
    "    chinese_df['neutral'] = len([row for row in chinese_data if row['label'] == 'neutral'])\n",
    "\n",
    "    arabic_df = pd.DataFrame(arabic_data)\n",
    "    arabic_df['positive'] = len([row for row in arabic_data if row['label'] == 'positive'])\n",
    "    arabic_df['negative'] = len([row for row in arabic_data if row['label'] == 'negative'])\n",
    "    arabic_df['neutral'] = len([row for row in arabic_data if row['label'] == 'neutral'])\n",
    "\n",
    "    # Return the DataFrames\n",
    "    return chinese_df, arabic_df\n",
    "\n",
    "# Call the function and assign the returned DataFrames\n",
    "chinese_df, arabic_df = create_df_by_language(data)\n",
    "\n",
    "# Print the DataFrames after they are created\n",
    "print(\"CHINESE DATAFRAME:\")\n",
    "print(chinese_df)\n",
    "print(\"ARABIC DATAFRAME:\")\n",
    "print(arabic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1035d2-f42b-41b1-a3a8-9c459c51d753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f344e85-6b21-43d0-9de7-4c71b964fdb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa83e92d-549c-4faf-b364-9525c352c2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9dea304-c6ec-4256-ae20-9c0a6823947c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chinese_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mchinese_df\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chinese_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(chinese_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e07036-aa1a-44dd-9cab-9869044acc98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84feff02-9b35-4c9b-8b0c-9ed5825b1871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde5a8b-265f-4143-8c58-8509a85231b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c397ac3b-64b2-4c91-9f84-04d88af81f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ced58f6-b3f8-4470-ba54-ed8fc0570037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# def analyze_sentiment_and_get_results(translated_headlines):\n",
    "#   sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\")\n",
    "#   results = []\n",
    "\n",
    "#   for language, headlines in translated_headlines.items():\n",
    "#     for headline in headlines:\n",
    "#       sentiment = sentiment_pipeline(headline)\n",
    "#       # Extract label and score\n",
    "\n",
    "#       label = sentiment[0]['label']\n",
    "#       score = sentiment[0]['score']\n",
    "\n",
    "#     # return analyzed_headlines\n",
    "        \n",
    "#       # Create a dictionary for each headline and its analysis\n",
    "#       result = {\n",
    "#         'language': language,\n",
    "#           \"text\": headline,\n",
    "#           \"label\": label,\n",
    "#           \"score\": score,\n",
    "#       }\n",
    "#       results.append(result)\n",
    "#   return results\n",
    "\n",
    "# # Assuming translated_headlines is your dictionary of translated headlines\n",
    "# results = analyze_sentiment_and_get_results(translated_headlines)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e25a00-8a46-4193-a704-94eb5ace7f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in results: \n",
    "#     if row['label'] == 'negative':\n",
    "#         if row['score'] > 0.7:\n",
    "#             row['categ_score'] = -2\n",
    "#         else: \n",
    "#             row['categ_score'] = -1\n",
    "#     elif row['label'] == 'positive':\n",
    "#         if row['score'] > 0.7:\n",
    "#             row['categ_score'] = 3\n",
    "#         else:\n",
    "#             row['categ_score'] = 2\n",
    "#     else:\n",
    "#         row['categ_score'] = 1\n",
    "# print(results[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e54316-8c86-4562-a138-58c2ca1f1b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "\n",
    "# chinese_data = []\n",
    "# arabic_data = []\n",
    "\n",
    "# # Iterate through the results and add elements to respective lists\n",
    "# for item in results:\n",
    "#   if item[\"language\"] == \"chinese\":\n",
    "#     chinese_data.append(item)\n",
    "#   elif item[\"language\"] == \"arabic\":\n",
    "#     arabic_data.append(item)\n",
    "\n",
    "# # Create DataFrames from lists\n",
    "# chinese_df = pd.DataFrame(chinese_data)\n",
    "# arabic_df = pd.DataFrame(arabic_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7683033-80d0-47f9-b744-16f0e04d9399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the DataFrames\n",
    "# print(\"Chinese headlines:\")\n",
    "# print(chinese_df)\n",
    "# print(\"\\nArabic headlines:\")\n",
    "# print(arabic_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2f57da-4176-4bdd-9881-d8eeb65823d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chinese_df.to_csv(\"chinese.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadeb916-f1df-40c4-ba6e-08d0b32607c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arabic_df.to_csv(\"arabic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195911e-8956-4151-a340-66d624e0ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f00c5b-43d3-456e-a8bc-c2bb85a4acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a498be-fa04-4ebd-affa-3a71685ca11e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0c34d5-9c9a-436c-b316-056b141b7bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b186aa2-5456-4335-ae86-7715c5e2ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# def analyze_sentiment_and_print(translated_headlines):\n",
    "#     sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\")\n",
    "    \n",
    "#     for language, headlines in translated_headlines.items():\n",
    "#         # print(f\"Language: {language}\")\n",
    "#         for headline in headlines:\n",
    "#             sentiment = sentiment_pipeline(headline)\n",
    "#             print(f\"Language: {language}\")\n",
    "#             print(f\"Headline: '{headline}'\")\n",
    "#             print(f\"Label: {sentiment[0]['label']}, Score: {sentiment[0]['score']:.2f}\")\n",
    "#             print(\"---\")  # Separator for readability\n",
    "#     # return analyzed_headlines\n",
    "# # Assuming translated_headlines is your dictionary of translated headlines\n",
    "# analyze_sentiment_and_print(translated_headlines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38495cdc-6a28-4565-9829-43028fe4a396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e2bfe6-2aec-4dd7-9cc5-809f593a46c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in results: \n",
    "#     if row['label'] == 'negative':\n",
    "#         if row['score'] > 0.7:\n",
    "#             row['categ_score'] = -2\n",
    "#         else: \n",
    "#             row['categ_score'] = -1\n",
    "#     elif row['label'] == 'positive':\n",
    "#         if row['score'] > 0.7:\n",
    "#             row['categ_score'] = 3\n",
    "#         else:\n",
    "#             row['categ_score'] = 2\n",
    "#     else:\n",
    "#         row['categ_score'] = 1\n",
    "# print(results[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb51d9-3f70-4393-b131-548a375dab02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d99ff4-6bef-45df-a87f-fc3a97628a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efd42c3-0f53-43dc-8d10-5afafc9e95df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7d0b0e-f36f-44b4-8a04-1b1d7c89acc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc920a91-5d3f-4d05-868c-8711de89916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# resultsdf = pd.DataFrame(results)\n",
    "# resultsdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ebbe5f-6469-4d47-8b67-e0cb673b5030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What I'm going to work next: \n",
    "# Find free websites in German, French, Spanish, Russian\n",
    "# Translate all the main headlines \n",
    "# Do a sentiment analysis on the headlines using a LLM\n",
    "# calculate the avg and median scores for each language\n",
    "#COMPARE the total score for each language's website "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5af7c19-d0b0-4f31-91ba-1f8a08bc13a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIND PYTHON library to visualize DIRECTLY on jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e8d263-6f40-4bbc-9f38-2d621444f71c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
